<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>TD2: Partitionnement avec l'algorithme des k-Means</title>
<meta name="author" content="Roland Donat" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<link rel="stylesheet" type="text/css" href="https://roland-donat.github.io/ubs/Charte_graphique/IUT/ubs_iut_vannes.css" />
</head>
<body>
<div id="content" class="content">
<h1 class="title">TD2: Partitionnement avec l'algorithme des k-Means</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgb71ec06">Introduction</a></li>
<li><a href="#org6f403a2">Modules <code>Python</code> utilisés dans ce TD</a></li>
<li><a href="#orgaf4eccc">Exercice 1 : Données <code>Wine</code></a>
<ul>
<li><a href="#org538860a">Chargement des données</a></li>
<li><a href="#org8fd4de3">Moyennes mobiles</a></li>
<li><a href="#org4ec8491">Partitionnement sur données centrées-réduites</a></li>
<li><a href="#org09a8a69">Partitionnement dans l'espace de l'ACP</a></li>
</ul>
</li>
<li><a href="#orgc69664b">Exercice 2 : Compression d'images</a>
<ul>
<li><a href="#org5af9bfe">Chargement d'une image</a></li>
<li><a href="#org57d45ff">Application des moyennes mobiles</a></li>
<li><a href="#org0ae0ca5">Méthode du coude</a></li>
</ul>
</li>
<li><a href="#org35237bb">Exercice 3 : Implémentation des moyennes mobiles</a></li>
</ul>
</div>
</div>

<div id="orgbf46a55" class="figure">
<p><img src="./kmeans.png" alt="kmeans.png" width="75%" />
</p>
<p><span class="figure-number">Figure&nbsp;1&nbsp;: </span><i>kmeans clustering spectacular application hyperrealistic white background</i> (image générée par Midjourney)</p>
</div>


<div id="outline-container-orgb71ec06" class="outline-2">
<h2 id="orgb71ec06">Introduction</h2>
<div class="outline-text-2" id="text-orgb71ec06">
<p>
L'objectif de ce TD est d'expérimenter les méthodes de partitionnement en utilisant en particulier
l'algorithme des moyennes mobiles (k-<i>Means</i>).
</p>

<p>
Nous testerons ces méthodes avec différents jeux de données afin d'illustrer leurs propriétés
caractéristiques. 
</p>

<p>
Enfin, nous tenterons d'implémenter notre propre version de l'algorithme k-<i>Means</i> en <code>Python</code>.
</p>
</div>
</div>

<div id="outline-container-org6f403a2" class="outline-2">
<h2 id="org6f403a2">Modules <code>Python</code> utilisés dans ce TD</h2>
<div class="outline-text-2" id="text-org6f403a2">
<p>
Dans ce TD, nous utiliserons les modules <code>Python</code> suivants :
</p>
<ul class="org-ul">
<li><code>pandas</code>, pour la manipulation des données ;</li>
<li><code>plotly</code>, pour les représentations graphiques ;</li>
<li><code>numpy</code>, pour utiliser des fonctions de calculs numériques "bas niveau", e.g. génération de
nombres aléatoires ;</li>
<li><code>scikit-learn</code>, pour les algorithmes de <i>machine learning</i> (dont k-<i>Means</i>).</li>
</ul>

<p>
Ces modules ne sont pas forcément installés dans votre environnement local ou distant. Vous pouvez
donc utiliser la commande <code>!pip install &lt;nom_module&gt;</code> pour les installer : 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">&#192; d&#233;commenter si besoin</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install pandas=='1.1.5'</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install plotly=='4.14.3'</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install scikit-learn=='0.24.1'</span>
</pre>
</div>


<p>
Rappel : code d'import des modules :
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> pandas <span style="color: #F0DFAF; font-weight: bold;">as</span> pd  <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Manipulation des donn&#233;es</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul num&#233;rique</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> plotly <span style="color: #F0DFAF; font-weight: bold;">as</span> pl <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Librairie principale pour avoir le n&#176; de version</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> plotly.express <span style="color: #F0DFAF; font-weight: bold;">as</span> px <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package plotly pour utiliser les visualisations de haut niveau</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> plotly.io <span style="color: #F0DFAF; font-weight: bold;">as</span> pio           <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">N&#233;cessaire avec Spyder</span>
<span style="color: #DFAF8F;">pio.renderers.default</span> = <span style="color: #CC9393;">'browser'</span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">N&#233;cessaire avec Spyder</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn <span style="color: #F0DFAF; font-weight: bold;">as</span> sk <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Librairie principale pour avoir le n&#176; de version</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn.cluster <span style="color: #F0DFAF; font-weight: bold;">as</span> skc <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package sklearn d&#233;di&#233; au clustering</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn.decomposition <span style="color: #F0DFAF; font-weight: bold;">as</span> skd   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package sklearn d&#233;di&#233; aux m&#233;thodes factorielles</span>

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">V&#233;rification des versions des librairies utilis&#233;es</span>
{<span style="color: #CC9393;">"plotly"</span>: pl.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"pandas"</span>: pd.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"numpy"</span>: np.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"sklearn"</span>: sk.__version__}
</pre>
</div>
</div>
</div>

<div id="outline-container-orgaf4eccc" class="outline-2">
<h2 id="orgaf4eccc">Exercice 1 : Données <code>Wine</code></h2>
<div class="outline-text-2" id="text-orgaf4eccc">
<p>
Nous allons reprendre les données des analyses chimiques sur le vin. Les données sont
<a href="https://roland-donat.github.io/cours-class-non-sup/td/td2/wine.csv">disponibles à ici</a>.
</p>
</div>

<div id="outline-container-org538860a" class="outline-3">
<h3 id="org538860a">Chargement des données</h3>
<div class="outline-text-3" id="text-org538860a">
<ol class="org-ol">
<li><p>
Chargez les données <code>Wine</code> dans un <code>DataFrame</code> nommé <code>wine_ori_df</code> (<code>ori</code> pour originales).
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">wine_path</span> = <span style="color: #CC9393;">"https://roland-donat.github.io/cours-class-non-sup/td/td1/wine.csv"</span>
<span style="color: #DFAF8F;">wine_ori_df</span> = pd.read_csv(wine_path, sep=<span style="color: #CC9393;">","</span>)
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-org8fd4de3" class="outline-3">
<h3 id="org8fd4de3">Moyennes mobiles</h3>
<div class="outline-text-3" id="text-org8fd4de3">
<p>
Nous allons utiliser l'algorithme des moyennes mobiles (k-Means) afin de partitionner automatiquement nos vins à
partir de leurs caractéristiques physico-chimiques. Pour ce faire, le package <code>sklearn.cluster</code> (ou
<code>skc</code> pour nous) de la librairie <code>sklearn</code> propose une implémentation de l'algorithme k-Means dans
la classe <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"><code>skc.KMeans</code></a>.
</p>

<p>
La grande majorité des algorithmes/modèles de <i>machine learning</i> disponibles dans la librairie <code>sklearn</code>
fonctionne sur le principe suivant :
</p>
<ol class="org-ol">
<li>Initialisation de la classe de l'algorithme avec les paramètres nécessaires.</li>
<li>Utilisation de la méthode <code>fit</code> pour ajuster l'algorithme/modèle avec les données disponibles.</li>
<li>Utilisation optionnelle de la méthode <code>predict</code> pour les méthodes permettant de faire des
prédictions.</li>
</ol>

<p>
Dans la suite, nous déclinerons la démarche précédente dans le cas particulier de l'algorithme
k-Means :
</p>
<ol class="org-ol">
<li><p>
Initialiser l'algorithme des moyennes mobiles sur les données <code>wine_ori_df</code> :
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">km_ori</span> = skc.KMeans(n_clusters=3)
</pre>
</div>
<ul class="org-ul">
<li>L'objet <code>km_ori</code> représente l'algorithme des moyennes mobiles.</li>
<li>Le paramètre <code>n_clusters</code> permet
de configurer le nombre de groupes recherché. Dans cet exemple, l'algorithme est prêt pour
partitionner en 3 groupes.</li>
<li>Notons que pour l'instant, aucun traitement n'a été réalisé puisqu'aucune données n'a été mise
en relation avec notre objet <code>km_ori</code>.</li>
<li><b>Question :</b> D'après le cours, ne faut-il pas fournir un élément supplémentaire pour
initialiser l'algorithme ?</li>
</ul></li>

<li><p>
Utiliser ensuite la méthode <code>fit</code> pour lancer le partitionnement sur les données <code>wine_ori_df</code> :
</p>
<div class="org-src-container">
<pre class="src src-python">km_ori.fit(wine_ori_df)
</pre>
</div>
<ul class="org-ul">
<li>La méthode <code>fit</code> exécute l'algorithme des k-Means tel que vu en cours. Des partitionnements
alternés avec le calcul des centres associés sont effectués successivement jusqu'à la convergence de
l'algorithme.</li>
<li>Selon votre version de <code>sklearn</code>, un message <code>Warning</code> concernant l'initialisation de
l'algorithme peut apparaître. Ce message est à ignorer pour l'instant, nous reviendrons sur ce
sujet ultérieurement.</li>
<li><b>Note :</b> On pourra également désigner l'objet <code>km_ori</code> comme le <b>modèle</b> <code>km_ori</code>. En effet, on
rappelle que la méthode k-Means (et plus largement les méthodes de classification non
supervisée) servent à modéliser un ensemble d'individus à partir d'un ensemble restreint de
groupes d'individus.</li>
</ul></li>

<li><p>
Après partitionnement, l'objet <code>km_ori</code> possède de nouveaux attributs. Utiliser la
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">documentation de la classe KMeans</a>  pour comprendre la signification des attributs suivants :
</p>
<div class="org-src-container">
<pre class="src src-python">km_ori.labels_
</pre>
</div>
<div class="org-src-container">
<pre class="src src-python">km_ori.cluster_centers_
</pre>
</div>
<div class="org-src-container">
<pre class="src src-python">km_ori.inertia_
</pre>
</div></li>

<li><p>
Calculer l'inertie expliquée par la partition obtenue avec le modèle <code>km_ori</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale des donn&#233;es</span>
<span style="color: #DFAF8F;">wine_ori_it</span> = ((wine_ori_df - wine_ori_df.mean())**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1).<span style="color: #DCDCCC; font-weight: bold;">sum</span>()
<span style="color: #DFAF8F;">km_ori_ie</span> = 1 - km_ori.inertia_/wine_ori_it
</pre>
</div></li>

<li><p>
Représenter graphiquement la partition obtenue avec le modèle <code>km_ori</code> à l'aide d'un diagramme
en paires et analyser le résultat.
</p>
<div class="org-src-container">
<pre class="src src-python">px.scatter_matrix(wine_ori_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> color=km_ori.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>), 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> title=<span style="color: #CC9393;">"Partition km_ori"</span>).show()
</pre>
</div></li>

<li><p>
Analyser le profil moyen des groupes obtenus avec la partition <code>km_ori</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">km_ori_mean</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   pd.DataFrame(km_ori.cluster_centers_,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>columns=wine_ori_df.columns)
km_ori_mean
</pre>
</div></li>

<li><p>
Analyser à présent le profil statistique détaillé des groupes obtenus avec la partition <code>km_ori</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">km_ori_prof</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   wine_ori_df.groupby(km_ori.labels_).describe()
km_ori_prof
</pre>
</div></li>

<li><p>
Représenter graphiquement les profils des groupes sous la forme d'un boxplot.
</p>
<div class="org-src-container">
<pre class="src src-python">px.box(wine_ori_df, color=km_ori.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>),
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Profils des groupes obtenus par la classification km_ori"</span>).show()
</pre>
</div></li>

<li>Étudier le paramétrage de la classe <code>skc.kMeans</code>. Donner en particulier la signification des
paramètres :
<ul class="org-ul">
<li><code>init</code> ;</li>
<li><code>n_init</code> ;</li>
<li><code>max_iter</code> ;</li>
<li><code>tol</code> ;</li>
<li><code>random_state</code>.</li>
</ul></li>

<li><p>
Réalisez un second modèle <code>km_ori_2</code> paramétré comme suit :
</p>
<ul class="org-ul">
<li>recherche de 3 groupes ;</li>
<li>initialisation aléatoire (cf. paramètre <code>init</code>) contrôlée en fixant le paramètre <code>random_state</code> à la valeur
<code>12345</code> ;</li>
<li>initialisation unique, cf. paramètre <code>n_init</code>.</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_ori_2</span> = skc.KMeans(
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   n_clusters=3,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   init=<span style="color: #CC9393;">"random"</span>,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   n_init=1,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   random_state=12345,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   )
km_ori_2.fit(wine_ori_df)
</pre>
</div></li>

<li><p>
Calculer l'inertie expliquée par la partition obtenue avec le modèle <code>km_ori_2</code>. Comparer ce
résultat avec l'inertie expliquée par le modèle <code>km_ori</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_ori_2_ie</span> = 1 - km_ori_2.inertia_/wine_ori_it
</pre>
</div></li>

<li><p>
Représenter graphiquement la partition obtenue avec le modèle <code>km_ori_2</code> à l'aide d'un diagramme
en paires et comparer le résultat obtenu.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
px.scatter_matrix(wine_ori_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> color=km_ori_2.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>), 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> title=<span style="color: #CC9393;">"Partition km_ori_2"</span>).show()
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-org4ec8491" class="outline-3">
<h3 id="org4ec8491">Partitionnement sur données centrées-réduites</h3>
<div class="outline-text-3" id="text-org4ec8491">
<p>
Dans la section précédente, nous avons constaté que les partitions obtenues avec k-Means ne
reposaient uniquement que sur les valeurs de la variable <code>Proline</code>. L'échelle de cette variable
étant significativement supérieure à celle des autres variables, les calculs de distances entre les
individus réalisés en dimension 13 au cours de la procédure k-Means sont approximativement
identiques à des calculs de distance en dimension 1 sur la variable <code>Proline</code>. Ceci
explique pourquoi les partitions élaborées font ressortir des groupes sur les nuages de points
faisant intervenir la variable <code>Proline</code> uniquement.
</p>

<p>
Par conséquent, afin de limiter l'influence des échelles des variables, nous proposons de travailler
dans la suite sur des données centrées et réduites.à
</p>

<ol class="org-ol">
<li><p>
Centrer et réduire les données afin d'obtenir un nouveau DataFrame <code>wine_cr_df</code> (<code>cr</code> pour
centré-réduit).
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">wine_cr_df</span> = (wine_ori_df - wine_ori_df.mean())/wine_ori_df.std()
</pre>
</div></li>

<li><p>
Créer un modèle k-Means, nommé <code>km_cr</code>, permettant de partitionner les données en 3 groupes en
utilisant le paramétrage par défaut de la classe <code>skc.kMeans</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_cr</span> = skc.KMeans(n_clusters=3)
</pre>
</div></li>

<li><p>
Utiliser ensuite la méthode <code>fit</code> pour lancer le partitionnement sur les données <code>wine_cr_df</code> :
</p>
<div class="org-src-container">
<pre class="src src-python">km_cr.fit(wine_cr_df)
</pre>
</div></li>

<li><p>
Calculer l'inertie expliquée par la parition obtenue avec le modèle <code>km_cr</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale des donn&#233;es</span>
<span style="color: #DFAF8F;">wine_cr_it</span> = ((wine_cr_df - wine_cr_df.mean())**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1).<span style="color: #DCDCCC; font-weight: bold;">sum</span>()
<span style="color: #DFAF8F;">km_cr_ie</span> = 1 - km_cr.inertia_/wine_cr_it
</pre>
</div></li>

<li><p>
Représenter graphiquement la partition obtenue avec le modèle <code>km_cr</code> à l'aide d'un diagramme
en paires, analyser le résultat obtenu et comparer avec les partitions précédentes.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
px.scatter_matrix(wine_cr_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> color=km_cr.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>), 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> title=<span style="color: #CC9393;">"Partition km_cr"</span>).show()
</pre>
</div></li>

<li><p>
En déduire le profil moyen et le profil statistique complet des groupes obtenus avec la partition
<code>km_cr</code> dans l'espace centré-réduit.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_cr_mean</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   pd.DataFrame(km_cr.cluster_centers_,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>columns=wine_cr_df.columns)
km_cr_mean
</pre>
</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_cr_prof</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   wine_cr_df.groupby(km_cr.labels_).describe()
km_cr_prof
</pre>
</div></li>

<li><p>
En déduire le profil moyen et le profil statistique complet des groupes obtenus avec la partition
<code>km_cr</code> dans l'espace original (c'est à dire des données initiales sans transformation).
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_cr_ori_mean</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   wine_ori_df.groupby(km_cr.labels_).mean()
km_cr_ori_mean
</pre>
</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_cr_ori_prof</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   wine_ori_df.groupby(km_cr.labels_).describe()
km_cr_ori_prof
</pre>
</div></li>
</ol>


<ol class="org-ol">
<li><p>
Représenter et analyser graphiquement les profils des groupes sous la forme d'un boxplot. Dans
quel espace l'interprétation des profils est-elle la plus aisée ? L'espace centré-réduit ou
l'espace original ?
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Espace centr&#233;-r&#233;duit -&gt; profils interpr&#233;tables mais ne pas oublier de tenir compte du centrage/r&#233;duction</span>
px.box(wine_cr_df, color=km_cr.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>),
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Profils des groupes obtenus par la classification km_cr (espace centr&#233;-r&#233;duit)"</span>).show()
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Espace original -&gt; profils interpr&#233;tables directement du point de vu m&#233;tier</span>
px.box(wine_ori_df, color=km_cr.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>),
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Profils des groupes obtenus par la classification km_cr (espace original)"</span>).show()
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-org09a8a69" class="outline-3">
<h3 id="org09a8a69">Partitionnement dans l'espace de l'ACP</h3>
<div class="outline-text-3" id="text-org09a8a69">
<ol class="org-ol">
<li><p>
Réaliser une Analyse en Composantes Principales (ACP) sur les données centrées-réduites <code>wine_cr_df</code> en utilisant
la classe <code>PCA</code> du <i>package</i> <code>sklearn.decomposition</code> (ou <code>skd</code> pour nous).
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">wine_acp</span> = skd.PCA().fit(wine_cr_df)
wine_acp.explained_variance_ratio_
</pre>
</div></li>

<li><p>
Projeter les données dans l'espace de l'ACP en utilisant la méthode <code>transform</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">wine_acp_df</span> = pd.DataFrame(wine_acp.transform(wine_cr_df)) 
wine_acp_df
</pre>
</div></li>

<li><p>
Créer un DataFrame <code>wine_acp_2d_df</code> correspondant aux données centrées-réduites
projetées sur les deux premiers axes de l'ACP.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">wine_acp_2d_df</span> = wine_acp_df[[0, 1]]
</pre>
</div></li>

<li><p>
Représenter graphiquement le nuage de points des données <code>wine_acp_2d_df</code>.
</p>
<div class="org-src-container">
<pre class="src src-python">px.scatter(wine_acp_2d_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  x=0, y=1,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  labels={<span style="color: #CC9393;">"0"</span>:<span style="color: #CC9393;">"Axe ACP 1"</span>, <span style="color: #CC9393;">"1"</span>:<span style="color: #CC9393;">"Axe ACP 2"</span>},
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Projection des donn&#233;es sur les deux premiers axes de l'ACP"</span>).show()
</pre>
</div></li>

<li><p>
Réaliser un modèle k-Means, nommé <code>km_acp</code>, permettant de partitionner les données <code>wine_acp_2d_df</code>
en 3 groupes. Visualiser la partition obtenue.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_acp</span> = skc.KMeans(n_clusters=3).fit(wine_acp_2d_df)
px.scatter(wine_acp_2d_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  x=0, y=1,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  color=km_acp.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>),
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  labels={<span style="color: #CC9393;">"0"</span>:<span style="color: #CC9393;">"Axe ACP 1"</span>, <span style="color: #CC9393;">"1"</span>:<span style="color: #CC9393;">"Axe ACP 2"</span>},
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Partition km_acp"</span>).show()
</pre>
</div></li>

<li><p>
En déduire les profils moyens et statistiques complets des groupes obtenus dans l'espace
centré-réduit et l'espace original.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_acp_cr_mean</span> = wine_cr_df.groupby(km_acp.labels_).mean()
<span style="color: #DFAF8F;">km_acp_cr_prof</span> = wine_cr_df.groupby(km_acp.labels_).describe()

<span style="color: #DFAF8F;">km_acp_ori_mean</span> = wine_ori_df.groupby(km_acp.labels_).mean()
<span style="color: #DFAF8F;">km_acp_ori_prof</span> = wine_ori_df.groupby(km_acp.labels_).describe()
</pre>
</div></li>

<li><p>
Représenter et analyser graphiquement les profils des groupes sous la forme d'un boxplot. Dans
quel espace est-il le plus pertinent d'analyser les groupes obtenus ? L'espace de l'ACP, l'espace
centré-réduit, l'espace original ? 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Espace ACP -&gt; profils impossibles &#224; interpr&#233;ter</span>
px.box(wine_acp_2d_df, color=km_acp.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>),
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Profils des groupes obtenus par la classification km_acp (espace ACP)"</span>).show()
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Espace centr&#233;-r&#233;duit -&gt; profils interpr&#233;tables mais ne pas oublier de tenir compte du centrage/r&#233;duction</span>
px.box(wine_cr_df, color=km_acp.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>),
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Profils des groupes obtenus par la classification km_acp (espace centr&#233;-r&#233;duit)"</span>).show()
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Espace original -&gt; profils interpr&#233;tables directement du point de vu m&#233;tier</span>
px.box(wine_ori_df, color=km_acp.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>),
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Profils des groupes obtenus par la classification km_acp (espace original)"</span>).show()

</pre>
</div></li>

<li><p>
Calculer l'inertie expliquée par la partition <code>km_acp</code> dans l'espace de l'ACP, dans l'espace
centré-réduit et dans l'espace original.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Cr&#233;ation d'une fonction permettant d'&#233;valuer une partition</span>
<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">eval_partition</span>(data_df, partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #9FC59F;">"""</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   Entr&#233;es :</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - data_df (pandas.DataFrame) : Donn&#233;es quantitatives</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - partition (list, numpy.array ou pandas.Series) : partition des donn&#233;es</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   Sortie :</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - inertie_intra : inertie intra-classe de la partition</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - inertie_score : Inertie expliqu&#233;e par la partition entre 0 et 1</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   """</span>

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale des donn&#233;es (cf. TD1)</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">mu_data</span> = data_df.mean()
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">d2_data_mu</span> = ((data_df - mu_data)**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_totale</span> = d2_data_mu.<span style="color: #DCDCCC; font-weight: bold;">sum</span>()

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie interne aux classes (cf. TD1)</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_intra</span> = 0
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">for</span> cls, data_cls_df <span style="color: #F0DFAF; font-weight: bold;">in</span> data_df.groupby(partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Centre de gravit&#233; de la classe cls</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">mu_cls</span> = data_cls_df.mean()
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Distances au carr&#233; entre les donn&#233;es de la classe et le centre de la classe</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">d2_data_cls</span> = ((data_cls_df - mu_cls)**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Sommation pour obtenir l'inertie interne &#224; la classe</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_intra</span> += d2_data_cls.<span style="color: #DCDCCC; font-weight: bold;">sum</span>()
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Inertie expliqu&#233;e par la partition</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_score</span> = 1 - inertie_intra/inertie_totale

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">return</span> inertie_intra, inertie_score


<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Utilisation de la fonction pour calculer l'inertie expliqu&#233;e de la partition km_acp</span>
<span style="color: #DFAF8F;">km_acp_iw</span>, <span style="color: #DFAF8F;">km_acp_ie</span> = eval_partition(wine_acp_2d_df, km_acp.labels_)
<span style="color: #DFAF8F;">km_acp_cr_iw</span>, <span style="color: #DFAF8F;">km_acp_cr_ie</span> = eval_partition(wine_cr_df, km_acp.labels_)
<span style="color: #DFAF8F;">km_acp_ori_iw</span>, <span style="color: #DFAF8F;">km_acp_ori_cr_ie</span> = eval_partition(wine_ori_df, km_acp.labels_)
</pre>
</div></li>
</ol>
</div>
</div>
</div>


<div id="outline-container-orgc69664b" class="outline-2">
<h2 id="orgc69664b">Exercice 2 : Compression d'images</h2>
<div class="outline-text-2" id="text-orgc69664b">
<p>
Cet exercice propose d'explorer la façon dont les méthodes de classification non supervisée
peuvent être 
appliquées pour la compression d'images et en particulier à la problématique de quantification en
couleurs (<i>color quantization</i> en anglais). Ce traitement d'image vise à réduire le nombre de
couleurs dans une image sans pour autant changer son aspect visuel général.
</p>

<p>
D'un point de vue informatique, une image est une série de pixels représentés par trois coordonnées
associées à leur niveau de rouge, vert et bleu. Une image peut donc être considérée comme un tableau
de données quantitatives à trois dimensions.
</p>
</div>

<div id="outline-container-org5af9bfe" class="outline-3">
<h3 id="org5af9bfe">Chargement d'une image</h3>
<div class="outline-text-3" id="text-org5af9bfe">
<ol class="org-ol">
<li><p>
Installer et importer la <a href="https://scikit-image.org/docs/dev/user_guide/getting_started.html">librairie <code>skimage</code> </a> permettant de faire du traitement d'image : <code>import
   skimage.io</code>. 
</p>
<div class="org-src-container">
<pre class="src src-python">!pip install scikit-image
</pre>
</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> skimage                        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Librairie de traitement d'image</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> skimage.io                     <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package skimage d&#233;di&#233; au chargement et la sauvegarde des images</span>
</pre>
</div></li>

<li><p>
Utiliser la fonction <code>skimage.io.imread</code> pour lire ce <a href="https://roland-donat.github.io/cours-class-non-sup/td/td3/streetball.jpg">fichier image</a>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">image_path</span> = <span style="color: #CC9393;">"https://roland-donat.github.io/cours-class-non-sup/td/td2/streetball.jpg"</span>
<span style="color: #DFAF8F;">image_data</span> = skimage.io.imread(image_path)
px.imshow(image_data)
</pre>
</div></li>

<li><p>
Transformer l'image en un <code>DataFrame</code> à trois variables en utilisant la méthode <code>.reshape</code>
des <code>numpy.array</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">image_nb_pixels</span> = image_data.shape[0]*image_data.shape[1]
<span style="color: #DFAF8F;">image_data_2d</span> = image_data.reshape((image_nb_pixels, 3))
<span style="color: #DFAF8F;">image_data_df</span> = pd.DataFrame(image_data_2d, columns=[<span style="color: #CC9393;">"R"</span>, <span style="color: #CC9393;">"G"</span>, <span style="color: #CC9393;">"B"</span>])
</pre>
</div></li>
</ol>
</div>
</div>

<div id="outline-container-org57d45ff" class="outline-3">
<h3 id="org57d45ff">Application des moyennes mobiles</h3>
<div class="outline-text-3" id="text-org57d45ff">
<ol class="org-ol">
<li><p>
Appliquez la méthode des moyennes mobiles afin de partitionner les données de pixels en 4
classes. Le modèle k-Means utilisé sera appelé <code>km_image</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_image</span> = skc.KMeans(n_clusters=4).fit(image_data_df)
</pre>
</div></li>

<li><p>
Reconstruire une image en remplaçant chaque pixel par le centre de sa classe.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">image_data_clust</span> = km_image.cluster_centers_[km_image.labels_]
</pre>
</div></li>

<li><p>
Afficher l'image obtenue sans oublier de retransformer les données de pixels dans la forme de
l'image originale.
</p>
<div class="org-src-container">
<pre class="src src-python">px.imshow(image_data_clust.reshape(image_data.shape))
</pre>
</div></li>

<li>Recommencer le traitement en jouant sur le nombre de classes de la partition et tenter
d'interpréter les résultats.</li>
</ol>
</div>
</div>

<div id="outline-container-org0ae0ca5" class="outline-3">
<h3 id="org0ae0ca5">Méthode du coude</h3>
<div class="outline-text-3" id="text-org0ae0ca5">
<ol class="org-ol">
<li><p>
Partitionner l'image en faisant varier le nombre de classes et en calculant
les inerties expliquées correspondantes.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale</span>
<span style="color: #DFAF8F;">image_data_it</span> = ((image_data_df - image_data_df.mean())**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1).<span style="color: #DCDCCC; font-weight: bold;">sum</span>()

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">M&#233;thode du coude</span>
<span style="color: #DFAF8F;">inertie_ie</span> = []
<span style="color: #DFAF8F;">K_list</span> = <span style="color: #DCDCCC; font-weight: bold;">range</span>(2, 20)
<span style="color: #F0DFAF; font-weight: bold;">for</span> k <span style="color: #F0DFAF; font-weight: bold;">in</span> K_list:
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"# groupes = {k}"</span>)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul d'une partition &#224; k classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">km_image</span> = skc.KMeans(n_clusters=k, n_init=<span style="color: #CC9393;">'auto'</span>).fit(image_data_df)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   inertie_ie.append(1 - km_image.inertia_/image_data_it)
</pre>
</div></li>

<li><p>
Représenter graphiquement l'évolution de l'inertie expliquée en fonction du nombre de
classes. Comment interpréter l'inertie expliquée dans cette application ?
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Repr&#233;sentation graphique des r&#233;sultats</span>
px.line(x=K_list, y=inertie_ie, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   title=<span style="color: #CC9393;">"Inertie expliqu&#233;e vs nb de classes (m&#233;thode du coude)"</span>,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   markers=<span style="color: #BFEBBF;">True</span>,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   width=800, height=800)
</pre>
</div></li>
</ol>
</div>
</div>
</div>


<div id="outline-container-org35237bb" class="outline-2">
<h2 id="org35237bb">Exercice 3 : Implémentation des moyennes mobiles</h2>
<div class="outline-text-2" id="text-org35237bb">
<p>
Comme on ne maîtrise jamais vraiment un algorithme tant que l'on ne l'a pas programmé, cette
dernière partie propose de créer votre propre version de la méthode des moyennes mobiles.
</p>

<p>
Pour ce faire, il vous faudra créer les trois fonctions suivantes :
</p>

<ol class="org-ol">
<li><p>
La fonction <code>calcule_centres</code> qui calcule le centre de chaque classe à partir de données
quantitative et d'une partition.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">calcule_centres</span>(data, partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> data.groupby(partition).mean()
</pre>
</div></li>
<li><p>
La fonction <code>affecte_classe</code> qui prend en entrée des données et les centres des classes et qui
affecte à chaque individu la classe ayant le centre le plus proche au sens de la distance
euclidienne. La fonction <code>cdist</code> de package <code>scipy.spatial.distance</code> peut être très utile&#x2026;
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Pour faciliter le calcul des distances</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">avec la fonction scd.cdist</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> scipy.spatial.distance <span style="color: #F0DFAF; font-weight: bold;">as</span> scd 

<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">affecte_classe</span>(data, centres):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">dist_cls_centers</span> = scd.cdist(data, centres, metric=<span style="color: #CC9393;">"euclidean"</span>)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">return</span> dist_cls_centers.argmin(axis=1)
</pre>
</div></li>

<li><p>
La fonction <code>my_kmeans</code> qui prend en entrée des données et un nombre de classes et qui applique
la méthode des moyennes mobiles. L'initialisation est supposée aléatoire et on arrêtera
l'algorithme dès que la partition construite n'évolue plus entre deux itérations. Cette fonction
doit utiliser vos fonctions <code>calcule_centres</code> et <code>affecte_classe</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">my_kmeans</span>(data, K):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Partition initiale</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">partition</span> = np.random.choice(K, <span style="color: #DCDCCC; font-weight: bold;">len</span>(data))
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">critere_arret</span> = <span style="color: #BFEBBF;">False</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">while</span> <span style="color: #F0DFAF; font-weight: bold;">not</span> critere_arret:

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">On enregistre la derni&#232;re partition</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">partition_old</span> = partition
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul des nouveaux centres</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">centres = &lt;&#224; compl&#233;ter&gt;</span>

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Affectation des classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">partition = &lt;&#224; compl&#233;ter&gt;</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul du crit&#232;re d'arr&#234;t</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">critere_arret</span> = (partition == partition_old).<span style="color: #DCDCCC; font-weight: bold;">all</span>()

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> partition, centres
</pre>
</div></li>
<li>Utiliser votre algorithme sur les données des exercices précédents et comparer vos résultats avec
la méthode <code>KMeans</code> de <code>scikit-learn</code>.</li>
</ol>
</div>
</div>
</div>
</body>
</html>
