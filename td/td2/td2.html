<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>TD2: Méthodes de partitionnement</title>
<meta name="author" content="Roland Donat" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<link rel="stylesheet" type="text/css" href="https://roland-donat.github.io/ubs/Charte_graphique/IUT/ubs_iut_vannes.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">TD2: Méthodes de partitionnement</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org5ca6191">Introduction</a></li>
<li><a href="#org6184dd1">Modules <code>Python</code> utilisés dans ce TD</a></li>
<li><a href="#org4dbf7c5">Exercice 1 : Données <code>Wine</code></a>
<ul>
<li><a href="#orge8f7c9a">Préparation des données</a></li>
<li><a href="#org8558ef2">Moyennes mobiles</a></li>
<li><a href="#org0c80875">Mélange gaussien</a></li>
</ul>
</li>
<li><a href="#orgfad77f5">Exercice 2 : Données synthétiques</a>
<ul>
<li><a href="#org97d6b53">Données circulaires</a></li>
<li><a href="#orgd7fc2ba">Données elliptiques</a></li>
</ul>
</li>
<li><a href="#org3a78865">Exercice 3 : Implémentation des moyennes mobiles</a></li>
</ul>
</div>
</div>

<div id="outline-container-org5ca6191" class="outline-2">
<h2 id="org5ca6191">Introduction</h2>
<div class="outline-text-2" id="text-org5ca6191">
<p>
L'objectif de ce TD est d'expérimenter les méthodes de partitionnement vues en cours, à savoir la
méthode des moyennes mobiles (k-<i>Means</i>) et la méthode du mélange gaussien. 
</p>

<p>
Nous testerons ces méthodes avec différents jeux de données afin d'illustrer leurs propriétés
caractéristiques. 
</p>

<p>
Enfin, nous tenterons d'implémenter notre propre version de l'algorithme k-<i>Means</i> en <code>Python</code>.
</p>
</div>
</div>

<div id="outline-container-org6184dd1" class="outline-2">
<h2 id="org6184dd1">Modules <code>Python</code> utilisés dans ce TD</h2>
<div class="outline-text-2" id="text-org6184dd1">
<p>
Dans ce TD, nous utiliserons les modules <code>Python</code> suivants :
</p>
<ul class="org-ul">
<li><code>pandas</code>, pour la manipulation des données ;</li>
<li><code>plotly</code>, pour les représentations graphiques ;</li>
<li><code>numpy</code>, pour utiliser des fonctions de calculs numériques "bas niveau", e.g. génération de
nombres aléatoires ;</li>
<li><code>sklearn</code>, pour les algorithmes de <i>machine learning</i> (k-<i>Means</i>, mélange gaussien, ou autres).</li>
</ul>

<p>
Ces modules ne sont pas forcément installés dans votre environnement local ou distant. Vous pouvez
donc utiliser la commande <code>!pip install &lt;nom_module&gt;</code> pour les installer : 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">&#192; d&#233;commenter si besoin</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install pandas=='1.1.5'</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install plotly=='4.14.3'</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install scikit-learn=='0.24.1'</span>
</pre>
</div>


<p>
Rappel : code d'import des modules :
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> pandas <span style="color: #F0DFAF; font-weight: bold;">as</span> pd  <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Manipulation des donn&#233;es</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul num&#233;rique</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> plotly <span style="color: #F0DFAF; font-weight: bold;">as</span> pl <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Librairie principale pour avoir le n&#176; de version</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> plotly.express <span style="color: #F0DFAF; font-weight: bold;">as</span> px <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package plotly pour utiliser les visualisations de haut niveau</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn <span style="color: #F0DFAF; font-weight: bold;">as</span> sk <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Librairie principale pour avoir le n&#176; de version</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn.cluster <span style="color: #F0DFAF; font-weight: bold;">as</span> skc <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package sklearn d&#233;di&#233; au clustering</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn.mixture <span style="color: #F0DFAF; font-weight: bold;">as</span> skm <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package sklearn d&#233;di&#233; aux mod&#232;les de m&#233;lange</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn.decomposition <span style="color: #F0DFAF; font-weight: bold;">as</span> skd   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package sklearn d&#233;di&#233; aux m&#233;thodes factorielles</span>

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">V&#233;rification des versions des librairies utilis&#233;es</span>
{<span style="color: #CC9393;">"plotly"</span>: pl.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"pandas"</span>: pd.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"numpy"</span>: np.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"sklearn"</span>: sk.__version__}
</pre>
</div>
</div>
</div>


<div id="outline-container-org4dbf7c5" class="outline-2">
<h2 id="org4dbf7c5">Exercice 1 : Données <code>Wine</code></h2>
<div class="outline-text-2" id="text-org4dbf7c5">
<p>
Nous allons reprendre les données des analyses chimiques sur le vin. Les données sont
<a href="https://roland-donat.github.io/cours-class-non-sup/td/td2/wine.csv">disponibles à ici</a>.
</p>
</div>

<div id="outline-container-orge8f7c9a" class="outline-3">
<h3 id="orge8f7c9a">Préparation des données</h3>
<div class="outline-text-3" id="text-orge8f7c9a">
<ol class="org-ol">
<li>Chargez les données <code>Wine</code> dans un <code>DataFrame</code> nommé <code>data_wine_ori_df</code> (<code>ori</code> pour originales).</li>

<li>Créez le <code>DataFrame</code> <code>data_wine_df</code> correspondant aux données <code>Wine</code> centrées et réduites.
<b>Note:</b> On rappelle que l'étape de centrage et de réduction n'est pas obligatoire pour faire un
partitionnement. En revanche, ce traitement est ici utile pour limiter l'influence de l'echelle
de certaines variables.</li>

<li><p>
Réaliser une Analyse en Composantes Principales (ACP) sur les données <code>data_wine_df</code> en analysant rapidement le résultat obtenu. Aide :
utilisez la classe <code>PCA</code> du <i>package</i> <code>sklearn.decomposition</code> (ou <code>skd</code> pour nous). 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">data_wine_acp</span> = skd.PCA().fit(data_wine_df)
<span style="color: #DFAF8F;">data_wine_acp_df</span> = pd.DataFrame(data_wine_acp.transform(data_wine_df), 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   columns=[f<span style="color: #CC9393;">"X{i+1}"</span> <span style="color: #F0DFAF; font-weight: bold;">for</span> i <span style="color: #F0DFAF; font-weight: bold;">in</span> <span style="color: #DCDCCC; font-weight: bold;">range</span>(<span style="color: #DCDCCC; font-weight: bold;">len</span>(data_wine_df.columns))])
data_wine_acp_df.head()
</pre>
</div></li>

<li><p>
Créez un <code>DataFrame</code> <code>data_wine_acp_2d_df</code> correspondant aux données
<code>Wine</code> projetées sur les deux premiers axes de l'ACP.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">data_wine_acp_2d_df</span> = &lt;&#224; compl&#233;ter&gt;
</pre>
</div></li>

<li><p>
Représentez graphiquement le nuage de points des données <code>data_wine_acp_2d_df</code>.
</p>
<div class="org-src-container">
<pre class="src src-python">px.scatter(&lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Projection des donn&#233;es sur les deux premiers axes de l'ACP"</span>)
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-org8558ef2" class="outline-3">
<h3 id="org8558ef2">Moyennes mobiles</h3>
<div class="outline-text-3" id="text-org8558ef2">
<ol class="org-ol">
<li><p>
Appliquez l'algorithme des moyennes mobiles sur les données <code>data_wine_acp_2d_df</code> en recherchant \(K=3\) groupes en
utilisant les paramètres par défaut. On notera <code>km_1</code> ce premier "modèle" de <i>clustering</i>.
</p>
<ul class="org-ul">
<li>Aide : utilisez la classe <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"><code>KMeans</code></a> du package <code>sklearn.cluster</code> (ou <code>skc</code> pour nous).</li>
<li>Prenez le temps de bien comprendre le fonctionnement et les concepts de la librairie
<code>scikit-learn</code> associés aux  algorithmes de classification (méthode <code>fit</code>, entrées/sorties,
etc.).</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">km_1</span> = skc.KMeans(n_clusters=3)
km_1.fit(data_wine_acp_2d_df)
&lt;Analysez le contenu de l<span style="color: #CC9393;">'objet km_1&gt;</span>
</pre>
</div></li>

<li>Représentez graphiquement la partition obtenue avec le modèle <code>km_1</code>.</li>

<li>Créez une fonction <code>eval_partition</code> ayant les caractéristiques suivantes :
<ul class="org-ul">
<li>Entrées :
<ul class="org-ul">
<li>des données quantitatives sous forme de <code>DataFrame</code> <code>Pandas</code> ;</li>
<li>une partition sous forme de <code>Series</code> <code>Pandas</code>.</li>
</ul></li>
<li>Retourne :
<ul class="org-ul">
<li>l'inertie intra-classe de la partition dans le cas de données équipondérées de poids 1 ;</li>
<li>le pourcentage d'inertie expliquée par la partition.</li>
</ul></li>
</ul></li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">eval_partition</span>(data_df, partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #9FC59F;">"""</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   Entr&#233;es :</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - data_df (pandas.DataFrame) : Donn&#233;es quantitatives</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - partition (list, numpy.array ou pandas.Series) : partition des donn&#233;es</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   Sortie :</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - inertie_intra : inertie intra-classe de la partition</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - inertie_score : Inertie expliqu&#233;e par la partition entre 0 et 1</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   """</span>

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale des donn&#233;es (cf. TD1)</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">-&gt; Calcul du centre de gravit&#233; des donn&#233;es</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">-&gt; Calcul des distances au carr&#233; entre les donn&#233;es et le centre de gravit&#233;</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">-&gt; D&#233;duction de l'inertie totale</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_totale</span> = &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie interne aux classes (cf. TD1)</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_intra</span> = 0
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">for</span> cls, data_cls_df <span style="color: #F0DFAF; font-weight: bold;">in</span> data_df.groupby(partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">On rappelle que dans la boucle :</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">- la variable cls contient le label de chaque classe</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">- la variable data_cls_df est un DataFrame contenant les individus</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;">#   </span><span style="color: #7F9F7F;">de la classe cls</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie interne &#224; la classe cls</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">-&gt; Calcul du centre de gravit&#233; des donn&#233;es de la classe cls</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">-&gt; Calcul des distances au carr&#233; entre les donn&#233;es de la classe cls et </span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;">#    </span><span style="color: #7F9F7F;">le centre de gravit&#233; de la classe</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">-&gt; D&#233;duction de l'inertie interne</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Ajout de l'inertie interne de la classe cls &#224; l'inertie intra-classe</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_intra</span> += &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Inertie expliqu&#233;e par la partition</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_score</span> = &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">return</span> inertie_intra, inertie_score
</pre>
</div>

<ol class="org-ol">
<li>Utilisez votre fonction <code>eval_partition</code> sur la partition du modèle <code>km_1</code> et comparez avec les résultats
obtenus par la classe <code>KMeans</code>.</li>

<li>Réalisez un second modèle <code>km_2</code> :
<ul class="org-ul">
<li>utilisez une initialisation aléatoire contrôlée en fixant le paramètre <code>random_state</code> à la valeur
<code>12345</code> ;</li>
<li>l'algorithme ne doit tester qu'une initialisation, cf. paramètre <code>n_init</code> ;</li>
<li>représentez graphiquement la partition obtenue ;</li>
<li>comparez les résultats avec ceux du modèle <code>km_1</code>.</li>
</ul></li>

<li>Lancez la méthode <code>KMeans</code> en faisant varier le nombre de classes et représentez graphiquement les pourcentages
d'inertie expliqué correspondants. Quel est selon vous le nombre de classes pertinent pour ces
données ?</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">M&#233;thode du coude</span>
<span style="color: #DFAF8F;">inertie_intra</span> = []
<span style="color: #DFAF8F;">K_list</span> = <span style="color: #DCDCCC; font-weight: bold;">range</span>(2, 50)
<span style="color: #F0DFAF; font-weight: bold;">for</span> k <span style="color: #F0DFAF; font-weight: bold;">in</span> K_list:
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul d'une partition &#224; k classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">&#201;valuation de la partition &#224; k classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">iintra</span>, <span style="color: #DFAF8F;">iscore</span> = eval_partition(data_wine_acp_2d_df, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> inertie_intra.append(iintra)

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Repr&#233;sentation graphique des r&#233;sultats</span>
px.line(x=K_list, y=inertie_intra, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   title=<span style="color: #CC9393;">"Inertie intra-classe vs nb de classes (m&#233;thode du coude)"</span>,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   width=500, height=500)
</pre>
</div>
</div>
</div>

<div id="outline-container-org0c80875" class="outline-3">
<h3 id="org0c80875">Mélange gaussien</h3>
<div class="outline-text-3" id="text-org0c80875">
<ol class="org-ol">
<li>Estimez un modèle gaussien à trois classes sur les données en utilisant les paramètres par
défaut. Ce modèle sera notée <code>gmm_1</code>. Aide : utilisez la classe <a href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html">classe
<code>GaussianMixture</code> </a>du package <code>sklearn.mixture</code> (ou <code>skm</code> pour nous).</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">gmm_1</span> = skm.GaussianMixture(n_components=3)
gmm_1.fit(data_wine_acp_2d_df)
</pre>
</div>

<ol class="org-ol">
<li>Affichez les paramètres du modèle <code>gmm_1</code>. Aide : consultez les attributs <code>means_</code>,
<code>covariances_</code>, <code>weights_</code>.</li>

<li>Calculez la partition des données <code>data_wine_acp_2d_df</code> à partir du modèle <code>gmm_1</code>.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">gmm_1_cls_pred</span> = gmm_1.predict(data_wine_acp_2d_df)
</pre>
</div>

<ol class="org-ol">
<li>Représenter graphiquement la partition <code>gmm_1_cls_pred</code>.</li>

<li>Comparez vos résultats avec les partitions obtenues avec les moyennes mobiles. Que constatez vous ?</li>

<li>Adaptez à la méthode des mélanges le principe de la méthode du coude vue pour le choix du nombre
de classes dans le cas des moyennes mobiles. Aide : utilisez l'attribut <code>bic</code> comme critère de
qualité sans oublier bien sûr de comprendre à quoi correspond ce critère.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">M&#233;thode du coude</span>
<span style="color: #DFAF8F;">score</span> = []
<span style="color: #DFAF8F;">K_list</span> = <span style="color: #DCDCCC; font-weight: bold;">range</span>(2, 50)
<span style="color: #F0DFAF; font-weight: bold;">for</span> k <span style="color: #F0DFAF; font-weight: bold;">in</span> K_list:
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">gmm_k_test</span> = &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> score.append(gmm_k_test.bic(data_wine_acp_2d_df))

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Repr&#233;sentation graphique des r&#233;sultats</span>
px.line(x=K_list, y=score, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   title=<span style="color: #CC9393;">"BIC vs nb de classes (m&#233;thode du coude)"</span>,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   width=500, height=500)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-orgfad77f5" class="outline-2">
<h2 id="orgfad77f5">Exercice 2 : Données synthétiques</h2>
<div class="outline-text-2" id="text-orgfad77f5">
<p>
Afin de mieux appréhender les propriétés des différentes méthodes de partitionnement, nous allons
utiliser des données générées pour lesquelles nous avons contrôlé la forme de la distribution des
groupes. 
</p>

<p>
Nous pourrons ainsi évaluer les avantages et les limitations des méthodes sur des données dont on
maîtrise le partitionnement <i>a priori</i>.
</p>
</div>

<div id="outline-container-org97d6b53" class="outline-3">
<h3 id="org97d6b53">Données circulaires</h3>
<div class="outline-text-3" id="text-org97d6b53">
<ol class="org-ol">
<li>Chargez les données <code>data_circ.csv</code> à partir de l'adresse :
<a href="https://roland-donat.github.io/cours-class-non-sup/td/td2/data_circ.csv">https://roland-donat.github.io/cours-class-non-sup/td/td2/data_circ.csv</a>. Le séparateur utilisé
est le ";".</li>

<li>Visualisez les données. Combien de groupes identifiez vous ? Faites un résumé statistique visuel
des groupes.</li>

<li>Appliquez un partitionnement avec la méthode des moyennes mobiles et affichez le résultat.</li>

<li>Appliquez un partitionnement avec un mélange gaussien et affichez le résultat.</li>

<li>Évaluez les deux partitionnements obtenus et interprétez les résultats.</li>
</ol>
</div>
</div>

<div id="outline-container-orgd7fc2ba" class="outline-3">
<h3 id="orgd7fc2ba">Données elliptiques</h3>
<div class="outline-text-3" id="text-orgd7fc2ba">
<ol class="org-ol">
<li>Chargez les données <code>data_ellipse.csv</code> à partir de l'adresse :
<a href="https://roland-donat.github.io/cours-class-non-sup/td/td2/data_ellipse.csv">https://roland-donat.github.io/cours-class-non-sup/td/td2/data_ellipse.csv</a>. Le séparateur utilisé
est le ";".</li>

<li>Visualisez les données. Combien de groupes identifiez vous ? Faites un résumé statistique visuel
des groupes.</li>

<li>Appliquez un partitionnement avec la méthode des moyennes mobiles et affichez le résultat.</li>

<li>Appliquez un partitionnement avec un mélange gaussien et affichez le résultat.</li>

<li>Évaluez les deux partitionnements obtenus et interprétez les résultats.</li>

<li>Appliquez de nouveau la méthode du mélange gaussien en modifiant le paramètre
<code>covariance_type</code>. Visualisez et interprétez les résultats.</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org3a78865" class="outline-2">
<h2 id="org3a78865">Exercice 3 : Implémentation des moyennes mobiles</h2>
<div class="outline-text-2" id="text-org3a78865">
<p>
Comme on ne maîtrise jamais vraiment un algorithme tant que l'on ne l'a pas programmé, cette
dernière partie propose de créer votre propre version de la méthode des moyennes mobiles.
</p>

<p>
Pour ce faire, il vous faudra créer les trois fonctions suivantes :
</p>

<ol class="org-ol">
<li>La fonction <code>calcule_centres</code> qui calcule le centre de chaque classe à partir de données
quantitative et d'une partition.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">calcule_centres</span>(data, partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> centres
</pre>
</div>

<ol class="org-ol">
<li>La fonction <code>affecte_classe</code> qui prend en entrée des données et les centres des classes et qui
affecte à chaque individu la classe ayant le centre le plus proche au sens de la distance euclidienne.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">affecte_classe</span>(data, centres):

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> partition
</pre>
</div>

<ol class="org-ol">
<li>La fonction <code>mon_kmeans</code> qui prend en entrée des données et un nombre de classes et qui applique
la méthode des moyennes mobiles. L'initialisation est supposée aléatoire et on arrêtera
l'algorithme dès que la partition construite n'évolue plus entre deux itérations.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">my_kmeans</span>(data, K):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Partition initiale</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">partition</span> = np.random.choice(K, <span style="color: #DCDCCC; font-weight: bold;">len</span>(data))
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">critere_arret</span> = <span style="color: #BFEBBF;">False</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">while</span> critere_arret:
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Affectation des classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">centres</span> = &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul des nouveaux centres</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">partition</span> = &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul du crit&#232;re d'arr&#234;t</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">critere_arret</span> = &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> partition, centres
</pre>
</div>

<ol class="org-ol">
<li>Utilisez votre algorithme sur les données des exercices précédents et comparez vos résultats avec
la méthode <code>KMeans</code> de <code>scikit-learn</code>.</li>
</ol>
</div>
</div>
</div>
</body>
</html>
