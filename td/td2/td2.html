<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>TD2: Partitionnement avec l'algorithme des k-Means</title>
<meta name="author" content="Roland Donat" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<link rel="stylesheet" type="text/css" href="https://roland-donat.github.io/ubs/Charte_graphique/IUT/ubs_iut_vannes.css" />
</head>
<body>
<div id="content" class="content">
<h1 class="title">TD2: Partitionnement avec l'algorithme des k-Means</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org21cd963">Introduction</a></li>
<li><a href="#org9f98207">Modules <code>Python</code> utilisés dans ce TD</a></li>
<li><a href="#org4a5cf5f">Exercice 1 : Données <code>Wine</code></a>
<ul>
<li><a href="#org0faf0b4">Chargement des données</a></li>
<li><a href="#org6c8559d">Moyennes mobiles</a></li>
<li><a href="#org54c1fc7">Partitionnement sur données centrées-réduites</a></li>
<li><a href="#org6630dfd">Partionnement dans l'espace de l'ACP</a></li>
<li><a href="#orgedb4578">Méthode du coude</a></li>
</ul>
</li>
<li><a href="#org66cc042">Exercice 2 : Données synthétiques</a>
<ul>
<li><a href="#orgfb0ea0e">Données circulaires</a></li>
<li><a href="#org2bb26c9">Données elliptiques</a></li>
</ul>
</li>
<li><a href="#org22585ec">Exercice 3 : Implémentation des moyennes mobiles</a></li>
</ul>
</div>
</div>

<div id="org6941d73" class="figure">
<p><img src="./vigneronnes.png" alt="vigneronnes.png" width="50%" />
</p>
<p><span class="figure-number">Figure&nbsp;1&nbsp;: </span>Image générée par <a href="https://openai.com/dall-e-2/">DALL-E</a></p>
</div>


<div id="outline-container-org21cd963" class="outline-2">
<h2 id="org21cd963">Introduction</h2>
<div class="outline-text-2" id="text-org21cd963">
<p>
L'objectif de ce TD est d'expérimenter les méthodes de partitionnement en utilisant en particulier
l'algorithme des des moyennes mobiles (k-<i>Means</i>).
</p>

<p>
Nous testerons ces méthodes avec différents jeux de données afin d'illustrer leurs propriétés
caractéristiques. 
</p>

<p>
Enfin, nous tenterons d'implémenter notre propre version de l'algorithme k-<i>Means</i> en <code>Python</code>.
</p>
</div>
</div>

<div id="outline-container-org9f98207" class="outline-2">
<h2 id="org9f98207">Modules <code>Python</code> utilisés dans ce TD</h2>
<div class="outline-text-2" id="text-org9f98207">
<p>
Dans ce TD, nous utiliserons les modules <code>Python</code> suivants :
</p>
<ul class="org-ul">
<li><code>pandas</code>, pour la manipulation des données ;</li>
<li><code>plotly</code>, pour les représentations graphiques ;</li>
<li><code>numpy</code>, pour utiliser des fonctions de calculs numériques "bas niveau", e.g. génération de
nombres aléatoires ;</li>
<li><code>scikit-learn</code>, pour les algorithmes de <i>machine learning</i> (dont k-<i>Means</i>).</li>
</ul>

<p>
Ces modules ne sont pas forcément installés dans votre environnement local ou distant. Vous pouvez
donc utiliser la commande <code>!pip install &lt;nom_module&gt;</code> pour les installer : 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">&#192; d&#233;commenter si besoin</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install pandas=='1.1.5'</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install plotly=='4.14.3'</span>
<span style="color: #5F7F5F;">#</span><span style="color: #7F9F7F;">!pip install scikit-learn=='0.24.1'</span>
</pre>
</div>


<p>
Rappel : code d'import des modules :
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> pandas <span style="color: #F0DFAF; font-weight: bold;">as</span> pd  <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Manipulation des donn&#233;es</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul num&#233;rique</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> plotly <span style="color: #F0DFAF; font-weight: bold;">as</span> pl <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Librairie principale pour avoir le n&#176; de version</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> plotly.express <span style="color: #F0DFAF; font-weight: bold;">as</span> px <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package plotly pour utiliser les visualisations de haut niveau</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn <span style="color: #F0DFAF; font-weight: bold;">as</span> sk <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Librairie principale pour avoir le n&#176; de version</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn.cluster <span style="color: #F0DFAF; font-weight: bold;">as</span> skc <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package sklearn d&#233;di&#233; au clustering</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> sklearn.decomposition <span style="color: #F0DFAF; font-weight: bold;">as</span> skd   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Package sklearn d&#233;di&#233; aux m&#233;thodes factorielles</span>

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">V&#233;rification des versions des librairies utilis&#233;es</span>
{<span style="color: #CC9393;">"plotly"</span>: pl.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"pandas"</span>: pd.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"numpy"</span>: np.__version__, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #CC9393;">"sklearn"</span>: sk.__version__}
</pre>
</div>
</div>
</div>

<div id="outline-container-org4a5cf5f" class="outline-2">
<h2 id="org4a5cf5f">Exercice 1 : Données <code>Wine</code></h2>
<div class="outline-text-2" id="text-org4a5cf5f">
<p>
Nous allons reprendre les données des analyses chimiques sur le vin. Les données sont
<a href="https://roland-donat.github.io/cours-class-non-sup/td/td2/wine.csv">disponibles à ici</a>.
</p>
</div>

<div id="outline-container-org0faf0b4" class="outline-3">
<h3 id="org0faf0b4">Chargement des données</h3>
<div class="outline-text-3" id="text-org0faf0b4">
<ol class="org-ol">
<li><p>
Chargez les données <code>Wine</code> dans un <code>DataFrame</code> nommé <code>wine_ori_df</code> (<code>ori</code> pour originales).
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">wine_path</span> = <span style="color: #CC9393;">"https://roland-donat.github.io/cours-class-non-sup/td/td1/wine.csv"</span>
<span style="color: #DFAF8F;">wine_ori_df</span> = pd.read_csv(wine_path, sep=<span style="color: #CC9393;">","</span>)
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-org6c8559d" class="outline-3">
<h3 id="org6c8559d">Moyennes mobiles</h3>
<div class="outline-text-3" id="text-org6c8559d">
<p>
Nous allons utiliser l'algorithme des moyennes mobiles (k-Means) afin de partionner automatiquement nos vins à
partir de leurs caractéristiques physico-chimiques. Pour ce faire, le package <code>sklearn.cluster</code> (ou
<code>skc</code> pour nous) de la librairie <code>sklearn</code> propose une implémentation de l'algorithme k-Means dans
la classe <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"><code>skc.KMeans</code></a>.
</p>

<p>
La grande majorité des algorithmes/modèles de <i>machine learning</i> disponibles dans la librairie <code>sklearn</code>
fonctionne sur le principe suivant :
</p>
<ol class="org-ol">
<li>Initialisation de la classe de l'algorithme avec les paramètres nécessaires.</li>
<li>Utilisation de la méthode <code>fit</code> pour ajuster l'algorithme/modèle avec les données disponibles.</li>
<li>Utilisation optionnelle de la méthode <code>predict</code> pour les méthodes permettant de faire des
prédictions.</li>
</ol>

<p>
Dans la suite, nous déclinerons la démarche précédente dans le cas particulier de l'algorithme
k-Means :
</p>
<ol class="org-ol">
<li><p>
Initialiser l'algorithme des moyennes mobiles sur les données <code>wine_ori_df</code> :
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">km_ori_1</span> = skc.KMeans(n_clusters=3)
</pre>
</div>
<ul class="org-ul">
<li>L'objet <code>km_ori_1</code> représente l'algorithme des moyennes mobiles.</li>
<li>Le paramètre <code>n_clusters</code> permet
de configurer le nombre de groupes recherché. Dans cet exemple, l'algorithme est prêt pour
partitionner en 3 groupes.</li>
<li>Notons que pour l'instant, aucun traitement n'a été réalisé puisqu'aucune données n'a été mise
en relation avec notre objet <code>km_ori_1</code>.</li>
<li><b>Question :</b> D'après le cours, ne faut-il pas fournir un élément supplémentaire pour
initialiser l'algorithme ?</li>
</ul></li>

<li><p>
Utiliser ensuite la méthode <code>fit</code> pour lancer le partitionnement sur les données <code>wine_ori_df</code> :
</p>
<div class="org-src-container">
<pre class="src src-python">km_ori_1.fit(wine_ori_df)
</pre>
</div>
<ul class="org-ul">
<li>La méthode <code>fit</code> exécute l'algorithme des k-Means tel que vu en cours. Des partitionnements
alternés avec le calcul des centres associés sont effectués successivement jusqu'à la convergence de
l'algorithme.</li>
<li>Selon votre version de <code>sklearn</code>, un message <code>Warning</code> concernant l'initialisation de
l'algorithme peut apparaître. Ce message est à ignorer pour l'instant, nous reviendrons sur ce
sujet ultiérieurement.</li>
<li><b>Note :</b> On pourra également désigner l'objet <code>km_ori_1</code> comme le <b>modèle</b> <code>km_ori_1</code>. En effet, on
rappelle que la méthode k-Means (et plus largement les méthodes de classification non
supervisée) servent à modéliser un ensemble d'individus à partir d'un ensemble restreint de
groupes d'individus.</li>
</ul></li>

<li><p>
Après paritionnement, l'objet <code>km_ori_1</code> possède de nouveaux attributs. Déduire (si besoin avec
l'aide de la documentation) la signification des attributs suivants :
</p>
<div class="org-src-container">
<pre class="src src-python">km_ori_1.labels_
</pre>
</div>
<div class="org-src-container">
<pre class="src src-python">km_ori_1.cluster_centers_
</pre>
</div>
<div class="org-src-container">
<pre class="src src-python">km_ori_1.inertia_
</pre>
</div></li>

<li><p>
Calculer l'initie expliquée par la parition obtenue avec le modèle <code>km_ori_1</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale des donn&#233;es</span>
<span style="color: #DFAF8F;">wine_ori_it</span> = ((wine_ori_df - wine_ori_df.mean())**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1).<span style="color: #DCDCCC; font-weight: bold;">sum</span>()
<span style="color: #DFAF8F;">km_ori_1_ie</span> = 1 - km_ori_1.inertia_/wine_ori_it
</pre>
</div></li>

<li><p>
Représenter graphiquement la partition obtenue avec le modèle <code>km_ori_1</code> à l'aide d'un diagramme
en paires et analyser le résultat.
</p>
<div class="org-src-container">
<pre class="src src-python">px.scatter_matrix(wine_ori_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> color=km_ori_1.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>), 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> title=<span style="color: #CC9393;">"Partition km_ori_1"</span>)
</pre>
</div></li>

<li><p>
Analyser le profil des groupes obtenus avec la partition <code>km_ori_1</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">km_ori_1_prof</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   pd.DataFrame(km_ori_1.cluster_centers_,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>columns=wine_ori_df.columns)
km_ori_1_prof
</pre>
</div></li>

<li><p>
Représenter graphiquement les profils des groupes sous la forme d'un boxplot.
</p>
<div class="org-src-container">
<pre class="src src-python">px.box(wine_ori_df, color=km_ori_1.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>))
</pre>
</div></li>

<li>Étudier les paramètres de la classe <code>skc.kMeans</code>. Donner en particulier la signification des
paramètres :
<ul class="org-ul">
<li><code>init</code> ;</li>
<li><code>n_init</code> ;</li>
<li><code>max_iter</code> ;</li>
<li><code>tol</code> ;</li>
<li><code>random_state</code>.</li>
</ul></li>

<li><p>
Réalisez un second modèle <code>km_ori_2</code> paramétré comme suit :
</p>
<ul class="org-ul">
<li>recherche de 3 groupes ;</li>
<li>initialisation aléatoire (cf. paramètre <code>init</code>) contrôlée en fixant le paramètre <code>random_state</code> à la valeur
<code>12345</code> ;</li>
<li>initialisation unique, cf. paramètre <code>n_init</code>.</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_ori_2</span> = skc.KMeans(
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   n_clusters=3,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   init=<span style="color: #CC9393;">"random"</span>,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   n_init=1,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   random_state=12345,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   )
km_ori_2.fit(wine_ori_df)
</pre>
</div></li>

<li><p>
Calculer l'initie expliquée par la parition obtenue avec le modèle <code>km_ori_2</code>. Comparer ce
résultat avec l'initie expliquée par le modèle <code>km_ori_1</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_ori_2_ie</span> = 1 - km_ori_2.inertia_/wine_ori_it
</pre>
</div></li>

<li><p>
Représenter graphiquement la partition obtenue avec le modèle <code>km_ori_2</code> à l'aide d'un diagramme
en paires et comparer le résultat obtenue.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
px.scatter_matrix(wine_ori_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> color=km_ori_2.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>), 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> title=<span style="color: #CC9393;">"Partition km_ori_2"</span>)
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-org54c1fc7" class="outline-3">
<h3 id="org54c1fc7">Partitionnement sur données centrées-réduites</h3>
<div class="outline-text-3" id="text-org54c1fc7">
<p>
Dans la section précédente, nous avons constaté que les partitions obtenues avec k-Means ne
reposaient uniquement que sur les valeurs de la variable <code>Proline</code>. L'échelle de cette variable
étant significativement supérieure à celle des autres variables, les calculs de distances entre les
individus réalisés en dimension 13 au cours de la procédure k-Means sont approximativement
identiques à des calculs de distance en dimension 1 sur la variable <code>Proline</code>. Ceci
explique pourquoi les partitions élaborées font ressortir des groupes sur les nuages de points
faisant intervenir la variable <code>Proline</code> uniquement.
</p>

<p>
Par conséquent, afin de limiter l'influence des échelles des variables, nous proposons de travailler
dans la suite sur des données centrées et réduites.à
</p>

<ol class="org-ol">
<li><p>
Centrer et réduire les données afin d'obtenir un nouveau DataFrame <code>wine_cr_df</code> (<code>cr</code> pour
centré-réduit).
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">wine_cr_df</span> = (wine_ori_df - wine_ori_df.mean())/wine_ori_df.std()
</pre>
</div></li>

<li><p>
Créer un modèle k-Means, nommé <code>km_cr_1</code>, permettant de partitionner les données en 3 groupes en
utilisant le paramétrage par défaut de la classe <code>skc.kMeans</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_cr_1</span> = skc.KMeans(n_clusters=3)
</pre>
</div></li>

<li><p>
Utiliser ensuite la méthode <code>fit</code> pour lancer le partitionnement sur les données <code>wine_cr_df</code> :
</p>
<div class="org-src-container">
<pre class="src src-python">km_cr_1.fit(wine_cr_df)
</pre>
</div></li>

<li><p>
Calculer l'initie expliquée par la parition obtenue avec le modèle <code>km_cr_1</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale des donn&#233;es</span>
<span style="color: #DFAF8F;">wine_cr_it</span> = ((wine_cr_df - wine_cr_df.mean())**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1).<span style="color: #DCDCCC; font-weight: bold;">sum</span>()
<span style="color: #DFAF8F;">km_cr_1_ie</span> = 1 - km_cr_1.inertia_/wine_cr_it
</pre>
</div></li>

<li><p>
Représenter graphiquement la partition obtenue avec le modèle <code>km_cr_1</code> à l'aide d'un diagramme
en paires, analyser le résultat obtenu et comparer avec les partitions précédentes.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
px.scatter_matrix(wine_cr_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> color=km_cr_1.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>), 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> title=<span style="color: #CC9393;">"Partition km_cr_1"</span>).show()
</pre>
</div></li>

<li><p>
Mettre sous la forme d'un DataFrame le profil moyen des groupes obtenus avec la partition <code>km_cr_1</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_cr_1_prof</span> = \
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   pd.DataFrame(km_cr_1.cluster_centers_,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>columns=wine_cr_df.columns)
km_cr_1_prof
</pre>
</div></li>

<li><p>
Représenter et analyser graphiquement les profils des groupes sous la forme d'un boxplot.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
px.box(wine_cr_df, color=km_cr_1.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>)).show()
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-org6630dfd" class="outline-3">
<h3 id="org6630dfd">Partionnement dans l'espace de l'ACP</h3>
<div class="outline-text-3" id="text-org6630dfd">
<ol class="org-ol">
<li><p>
Réaliser une Analyse en Composantes Principales (ACP) sur les données centrées-réduites <code>wine_cr_df</code> en utilisant
la classe <code>PCA</code> du <i>package</i> <code>sklearn.decomposition</code> (ou <code>skd</code> pour nous).
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">wine_acp</span> = skd.PCA().fit(wine_cr_df)
wine_acp.explained_variance_ratio_
</pre>
</div></li>

<li><p>
Projeter les données dans l'espace de l'ACP en utilisant la méthode <code>transform</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">wine_acp_df</span> = pd.DataFrame(wine_acp.transform(wine_cr_df)) 
wine_acp_df
</pre>
</div></li>

<li><p>
Créer un DataFrame <code>wine_acp_2d_df</code> correspondant aux données centrées-réduites
projetées sur les deux premiers axes de l'ACP.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">wine_acp_2d_df</span> = wine_acp_df[[0, 1]]
</pre>
</div></li>

<li><p>
Représenter graphiquement le nuage de points des données <code>wine_acp_2d_df</code>.
</p>
<div class="org-src-container">
<pre class="src src-python">px.scatter(wine_acp_2d_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  x=0, y=1,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  labels={<span style="color: #CC9393;">"0"</span>:<span style="color: #CC9393;">"Axe ACP 1"</span>, <span style="color: #CC9393;">"1"</span>:<span style="color: #CC9393;">"Axe ACP 2"</span>},
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Projection des donn&#233;es sur les deux premiers axes de l'ACP"</span>)
</pre>
</div></li>

<li><p>
Réaliser un modèle k-Means, nommé <code>km_acp_1</code>, permettant de partitionner les données <code>wine_acp_2d_df</code>
en 3 groupes. Visualiser la partition obtenue.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_acp_1</span> = skc.KMeans(n_clusters=3).fit(wine_acp_2d_df)
px.scatter(wine_acp_2d_df,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  x=0, y=1,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  color=km_acp_1.labels_,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  labels={<span style="color: #CC9393;">"0"</span>:<span style="color: #CC9393;">"Axe ACP 1"</span>, <span style="color: #CC9393;">"1"</span>:<span style="color: #CC9393;">"Axe ACP 2"</span>},
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>  title=<span style="color: #CC9393;">"Partition km_acp_1"</span>)
</pre>
</div></li>

<li><p>
En déduire le profil moyen des groupes obtenus dans l'espace centré-réduit.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #DFAF8F;">km_acp_1_prof</span> = wine_cr_df.groupby(km_acp_1.labels_).mean()
</pre>
</div></li>

<li><p>
Représenter et analyser graphiquement les profils des groupes sous la forme d'un boxplot.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
px.box(wine_cr_df, color=km_acp_1.labels_.astype(<span style="color: #DCDCCC; font-weight: bold;">str</span>)).show()
</pre>
</div></li>

<li><p>
Calculer l'inertie expliquée par la partition <code>km_acp_1</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">SOLUTION</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">--------</span>
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Cr&#233;ation d'une fonction permettant d'&#233;valuer une partition</span>
<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">eval_partition</span>(data_df, partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #9FC59F;">"""</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   Entr&#233;es :</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - data_df (pandas.DataFrame) : Donn&#233;es quantitatives</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - partition (list, numpy.array ou pandas.Series) : partition des donn&#233;es</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   Sortie :</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - inertie_intra : inertie intra-classe de la partition</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   - inertie_score : Inertie expliqu&#233;e par la partition entre 0 et 1</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span><span style="color: #9FC59F;">   """</span>

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie totale des donn&#233;es (cf. TD1)</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">mu_data</span> = data_df.mean()
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">d2_data_mu</span> = ((data_df - mu_data)**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_totale</span> = d2_data_mu.<span style="color: #DCDCCC; font-weight: bold;">sum</span>()

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul de l'inertie interne aux classes (cf. TD1)</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_intra</span> = 0
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">for</span> cls, data_cls_df <span style="color: #F0DFAF; font-weight: bold;">in</span> data_df.groupby(partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Centre de gravit&#233; de la classe cls</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">mu_cls</span> = data_cls_df.mean()
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Distances au carr&#233; entre les donn&#233;es de la classe et le centre de la classe</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">d2_data_cls</span> = ((data_cls_df - mu_cls)**2).<span style="color: #DCDCCC; font-weight: bold;">sum</span>(axis=1)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Sommation pour obtenir l'inertie interne &#224; la classe</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_intra</span> += d2_data_cls.<span style="color: #DCDCCC; font-weight: bold;">sum</span>()
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Inertie expliqu&#233;e par la partition</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">inertie_score</span> = 1 - inertie_intra/inertie_totale

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #F0DFAF; font-weight: bold;">return</span> inertie_intra, inertie_score


<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Utilisation de la fonction pour calculer l'inertie expliqu&#233;e de la partition km_acp_1</span>
<span style="color: #DFAF8F;">km_acp_1_iw</span>, <span style="color: #DFAF8F;">km_acp_1_ie</span> = eval_partition(wine_cr_df, km_acp_1.labels_)
</pre>
</div></li>
</ol>
</div>
</div>


<div id="outline-container-orgedb4578" class="outline-3">
<h3 id="orgedb4578">Méthode du coude</h3>
<div class="outline-text-3" id="text-orgedb4578">
<ol class="org-ol">
<li>Lancez la méthode <code>KMeans</code> en faisant varier le nombre de classes et représentez graphiquement les pourcentages
d'inertie expliqué correspondants. Quel est selon vous le nombre de classes pertinent pour ces
données ?</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">M&#233;thode du coude</span>
<span style="color: #DFAF8F;">inertie_intra</span> = []
<span style="color: #DFAF8F;">K_list</span> = <span style="color: #DCDCCC; font-weight: bold;">range</span>(2, 50)
<span style="color: #F0DFAF; font-weight: bold;">for</span> k <span style="color: #F0DFAF; font-weight: bold;">in</span> K_list:
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul d'une partition &#224; k classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">&#201;valuation de la partition &#224; k classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">iintra</span>, <span style="color: #DFAF8F;">iscore</span> = eval_partition(data_wine_acp_2d_df, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;)
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> inertie_intra.append(iintra)

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Repr&#233;sentation graphique des r&#233;sultats</span>
px.line(x=K_list, y=inertie_intra, 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   title=<span style="color: #CC9393;">"Inertie intra-classe vs nb de classes (m&#233;thode du coude)"</span>,
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   width=500, height=500)
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-org66cc042" class="outline-2">
<h2 id="org66cc042">Exercice 2 : Données synthétiques</h2>
<div class="outline-text-2" id="text-org66cc042">
<p>
Afin de mieux appréhender les propriétés des différentes méthodes de partitionnement, nous allons
utiliser des données générées pour lesquelles nous avons contrôlé la forme de la distribution des
groupes. 
</p>

<p>
Nous pourrons ainsi évaluer les avantages et les limitations des méthodes sur des données dont on
maîtrise le partitionnement <i>a priori</i>.
</p>
</div>

<div id="outline-container-orgfb0ea0e" class="outline-3">
<h3 id="orgfb0ea0e">Données circulaires</h3>
<div class="outline-text-3" id="text-orgfb0ea0e">
<ol class="org-ol">
<li>Chargez les données <code>data_circ.csv</code> à partir de l'adresse :
<a href="https://roland-donat.github.io/cours-class-non-sup/td/td2/data_circ.csv">https://roland-donat.github.io/cours-class-non-sup/td/td2/data_circ.csv</a>. Le séparateur utilisé
est le ";".</li>

<li>Visualisez les données. Combien de groupes identifiez vous ? Faites un résumé statistique visuel
des groupes.</li>

<li>Appliquez un partitionnement avec la méthode des moyennes mobiles et affichez le résultat.</li>

<li>Appliquez un partitionnement avec un mélange gaussien et affichez le résultat.</li>

<li>Évaluez les deux partitionnements obtenus et interprétez les résultats.</li>
</ol>
</div>
</div>

<div id="outline-container-org2bb26c9" class="outline-3">
<h3 id="org2bb26c9">Données elliptiques</h3>
<div class="outline-text-3" id="text-org2bb26c9">
<ol class="org-ol">
<li>Chargez les données <code>data_ellipse.csv</code> à partir de l'adresse :
<a href="https://roland-donat.github.io/cours-class-non-sup/td/td2/data_ellipse.csv">https://roland-donat.github.io/cours-class-non-sup/td/td2/data_ellipse.csv</a>. Le séparateur utilisé
est le ";".</li>

<li>Visualisez les données. Combien de groupes identifiez vous ? Faites un résumé statistique visuel
des groupes.</li>

<li>Appliquez un partitionnement avec la méthode des moyennes mobiles et affichez le résultat.</li>

<li>Appliquez un partitionnement avec un mélange gaussien et affichez le résultat.</li>

<li>Évaluez les deux partitionnements obtenus et interprétez les résultats.</li>

<li>Appliquez de nouveau la méthode du mélange gaussien en modifiant le paramètre
<code>covariance_type</code>. Visualisez et interprétez les résultats.</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org22585ec" class="outline-2">
<h2 id="org22585ec">Exercice 3 : Implémentation des moyennes mobiles</h2>
<div class="outline-text-2" id="text-org22585ec">
<p>
Comme on ne maîtrise jamais vraiment un algorithme tant que l'on ne l'a pas programmé, cette
dernière partie propose de créer votre propre version de la méthode des moyennes mobiles.
</p>

<p>
Pour ce faire, il vous faudra créer les trois fonctions suivantes :
</p>

<ol class="org-ol">
<li>La fonction <code>calcule_centres</code> qui calcule le centre de chaque classe à partir de données
quantitative et d'une partition.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">calcule_centres</span>(data, partition):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> centres
</pre>
</div>

<ol class="org-ol">
<li>La fonction <code>affecte_classe</code> qui prend en entrée des données et les centres des classes et qui
affecte à chaque individu la classe ayant le centre le plus proche au sens de la distance euclidienne.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">affecte_classe</span>(data, centres):

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> partition
</pre>
</div>

<ol class="org-ol">
<li>La fonction <code>mon_kmeans</code> qui prend en entrée des données et un nombre de classes et qui applique
la méthode des moyennes mobiles. L'initialisation est supposée aléatoire et on arrêtera
l'algorithme dès que la partition construite n'évolue plus entre deux itérations.</li>
</ol>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">my_kmeans</span>(data, K):
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Partition initiale</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">partition</span> = np.random.choice(K, <span style="color: #DCDCCC; font-weight: bold;">len</span>(data))
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #DFAF8F;">critere_arret</span> = <span style="color: #BFEBBF;">False</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> 
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">while</span> critere_arret:
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Affectation des classes</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">centres</span> = &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul des nouveaux centres</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">partition</span> = &lt;&#224; compl&#233;ter&gt;
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Calcul du crit&#232;re d'arr&#234;t</span>
<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span>   <span style="color: #DFAF8F;">critere_arret</span> = &lt;&#224; compl&#233;ter&gt;

<span style="color: #DCDCCC; background-color: #4F4F4F;"> </span> <span style="color: #F0DFAF; font-weight: bold;">return</span> partition, centres
</pre>
</div>

<ol class="org-ol">
<li>Utilisez votre algorithme sur les données des exercices précédents et comparez vos résultats avec
la méthode <code>KMeans</code> de <code>scikit-learn</code>.</li>
</ol>
</div>
</div>
</div>
</body>
</html>
