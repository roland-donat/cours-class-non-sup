# -*- coding: utf-8 -*-
#+TITLE: TD1: Introduction et notions fondamentales
#+AUTHOR: Roland Donat
#+EMAIL: roland.donat@univ-ubs.fr
# #+DATE: 

# ==============================================
# Document Configuration
# ======================
# Orgmode
:CONFIG:
#+LANGUAGE: fr
#+OPTIONS: H:3 num:t toc:t \n:nil @:t ::t |:t ^:{} f:t TeX:t author:t d:nil timestamp:nil
#+OPTIONS: html-postamble:nil
#+STARTUP: content 
#+STARTUP: hidestars
#+DRAWERS: CONFIG OPTIONS CACHE MACROS
#+TODO: TODO(t) INPROGRESS(p) | DONE(d)
#+BIND: org-latex-table-scientific-notation "{%s}E{%s}"
:END:

# LaTeX
# -----
# Class parameters
:CONFIG:
#+LaTeX_CLASS: ubs-note
#+LaTeX_CLASS_OPTIONS: [a4paper,twoside,11pt]
#+LATEX_HEADER: \thelang{FR}
#+LATEX_HEADER: \thesubtitle{}
#+LATEX_HEADER: \institution{IUT Vannes}
#+LATEX_HEADER: \course{Classification non supervisée}
#+LATEX_HEADER: \cursus{STID 2 - 2020-2021}
#+LATEX_HEADER: \version{1.0}
:END:
# Packages
:CONFIG:
#+LATEX_HEADER: \usepackage[french]{babel}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{amssymb}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amsfonts}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage{verbatim}
#+LATEX_HEADER: \usepackage{tabularx}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{lmodern}
#+LATEX_HEADER: \usepackage{natbib}
#+LATEX_HEADER: \usepackage{subfig}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{minted}
:END:
# Layout
:CONFIG:
# Figures path
#+LATEX_HEADER: % Graphics path
#+LATEX_HEADER: \graphicspath{ 
#+LATEX_HEADER:   {./fig/}
#+LATEX_HEADER: }

# Colors
#+LATEX_HEADER: \definecolor{almostwhite}        {rgb}{0.85,0.85,0.85}

# Minted
# To control spaces between minted block
#+LATEX_HEADER: \AtBeginEnvironment{snugshade*}{\vspace{-1.25\FrameSep}}
#+LATEX_HEADER: \AfterEndEnvironment{snugshade*}{\vspace{-2\FrameSep}}
# #+LATEX_HEADER: \usemintedstyle{monokai}
# #+LATEX_HEADER: \renewcommand{\theFancyVerbLine}{\sffamily \footnotesize {\color{EMLogoBlue}\oldstylenums{\arabic{FancyVerbLine}}}}

# Captions
#+LATEX_HEADER: \captionsetup[table]{position=bottom,margin=90pt,font=small,labelfont=bf,labelsep=endash,format=plain}
#+LATEX_HEADER: \captionsetup[figure]{position=bottom,margin=90pt,font=small,labelfont=bf,labelsep=endash,format=plain}
#+LATEX_HEADER: \captionsetup[subfloat]{margin=0pt,font=footnotesize}

# Geometry
#+LATEX_HEADER: \usepackage{geometry}
#+LATEX_HEADER: \geometry{
#+LATEX_HEADER: %  nohead,
#+LATEX_HEADER:   top=2.25cm, 
#+LATEX_HEADER:   bottom=2.25cm, 
#+LATEX_HEADER:  left=2.5cm, 
#+LATEX_HEADER:  right=2.5cm}

#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \onehalfspacing
#+LATEX_HEADER: % Supprime l'indentation
#+LATEX_HEADER: \setlength{\parindent}{0pt}
#+LATEX_HEADER: % Espacement entre les paragraphes
#+LATEX_HEADER: \setlength{\parskip}{2ex}

# List layout
#+LATEX_HEADER: \frenchbsetup{ListOldLayout=true} %FBReduceListSpacing=true,CompactItemize=false}

# References
#+LATEX: \renewcommand*{\refname}{}*
:END:
# LaTeX Compilator
:CONFIG:
#+BEGIN_SRC emacs-lisp :results silent :exports none
(setq org-latex-listings 'minted
      org-latex-minted-options nil ;; '(("frame" "lines")))
      org-latex-pdf-process
      '("xelatex -shell-escape -interaction nonstopmode -output-directory %o %f"
        "bibtex %b"
        "xelatex -shell-escape -interaction nonstopmode -output-directory %o %f"
        "xelatex -shell-escape -interaction nonstopmode -output-directory %o %f"))
#+END_SRC
:END:

# HTML
# ----
:CONFIG:
# Org HTML Macros
#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@
#+MACRO: HTMLFONTSIZE @@html:<font size="$2">$1</font>@@
#+MACRO: SUBTITLE @@html:<div class="slidesubtitle">$1</div>@@

# HTML options
# ------------
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://roland-donat.github.io/ubs/Charte_graphique/IUT/ubs_iut_vannes.css" />
# #+HTML_HEAD: <link rel="stylesheet" type="text/css" href="./ubs_iut_vannes.css" />
:END:

# Publishing
# ----------
:CONFIG:
#+BEGIN_SRC emacs-lisp :results silent :exports none
;; Define some export options here since in org-publish-project-alist some of them are not taken into account
;; e.g. with-toc nil
(defun my-html-export-options (plist backend)
  (cond 
    ((equal backend 'html)
     (plist-put plist :with-toc t)
     (plist-put plist :section-numbers nil)
     (plist-put plist :with-author t)
     (plist-put plist :with-email t)
     (plist-put plist :with-date t)
     ))
  plist)

(setq org-publish-project-alist
      '(
	
        ("main"
         :base-directory "./"
         :include ("rb_mod_stoch.org")
         :publishing-directory "./"
         :recursive nil
         :publishing-function org-html-publish-to-html
         :preparation-function (lambda () (setq org-export-filter-options-functions '(my-html-export-options)))
         :auto-preamble t
         :html-head  "<link rel='stylesheet' type='text/css' href='edgemind.css' />"
         :htmlized-source 
	 :section-numbers nil
         )
        ("td-html"
         :base-directory "./td/"
         :base-extension "org"
         :publishing-directory "./td"
         :recursive t
         :publishing-function org-html-publish-to-html
         :preparation-function (lambda () (setq org-export-filter-options-functions '(my-html-export-options)))
         :auto-preamble t
         :html-head  "<link rel='stylesheet' type='text/css' href='edgemind.css' />"
         :htmlized-source 
         )

	 ;; pdf
        ("td-pdf"
         :base-directory "./td/"
         :base-extension "org"
         :publishing-directory "./td"
         :recursive t
         :publishing-function org-latex-publish-to-pdf
         )

	 ("td-attach"
	 :base-directory "./td/"
	 :base-extension "xdsl\\|txt\\|csv\\|py\\|png"
         :publishing-directory "./td"
	 :recursive t
	 :publishing-function org-publish-attachment
	 )

	 ("cours-attach"
	 :base-directory "./cours/"
	 :base-extension "pdf\\|xdsl\\|txt\\|csv\\|py"
         :publishing-directory "./cours"
	 :recursive t
	 :publishing-function org-publish-attachment
	 )

        ("projet-html"
         :base-directory "./projet/"
         :base-extension "org"
         :publishing-directory "./projet"
         :recursive t
         :publishing-function org-html-publish-to-html
         :preparation-function (lambda () (setq org-export-filter-options-functions '(my-html-export-options)))
         :auto-preamble t
         :html-head  "<link rel='stylesheet' type='text/css' href='edgemind.css' />"
         :htmlized-source 
         )

	 ("projet-attach"
	 :base-directory "./projet/"
	 :base-extension "xdsl\\|txt\\|csv"
         :publishing-directory "./projet"
	 :recursive t
	 :publishing-function org-publish-attachment
	 )

	 ("css"
         :base-directory "./css/"
         :base-extension "css"
         :publishing-directory "./www/css"
         :publishing-function org-publish-attachment)
	 
	 ;("rb_mod_stoch" :components ("main" "td-pdf" "td-html" "td-attach" "cours-attach" "projet-html" "projet-attach" "css"))
	 ;("rb_mod_stoch" :components ("main" "td-pdf" "td-html" "projet-html"))
	 ("rb_mod_stoch" :components ("main"))

      ))
#+END_SRC
:END:

# ==============================================
# Document starts here
# ====================

#+LATEX: \clearpage

* Préambule

** Crédit

Ce TD reprend la trame du [[https://moodle.univ-ubs.fr/pluginfile.php/360513/mod_resource/content/2/TDR1.pdf][TD de classification non supervisée]] proposé par Mme. Arlette Antoni en
2019-2020. Le TD original était réalisé avec le logiciel =R= tandis que nous allons utiliser le
logiciel =Python=.

** Environnement logiciel

Les travaux se dérouleront sous =Python=. Si vous disposez d'une connexion internet, je vous
recommande d'utiliser une plateforme de /Notebooks/ en ligne telle que
[[https://deepnote.com][=DeepNote=]] sinon vous pouvez
toujours utiliser =Python= en local en installant la distribution [[https://www.anaconda.com/products/individual][=Anaconda=]]. L'important est de vous
assurer que vous utilisez bien la version =3.8= ou plus de =Python=.

* Introduction

L'objectif de ce TD est de mettre en pratique les principales notions vues en cours en les
appliquant sur un jeu de données réel.

Pour ce faire, nous utiliserons une adaptation des données libres [[https://archive.ics.uci.edu/ml/datasets/wine][Wine Data Set]] ne conservant que
les variables quantitatives pour la mise en oeuvre de méthodes de classification non supervisée.

Les données correspondent aux résultats d'analyses chimiques sur des vins issus d'une même région
d'Italie mais produits par trois vignerons différents. L'analyse quantifie la présence des 13
éléments suivants :  
- Alcohol
- Malic acid
- Ash
- Alcalinity of ash
- Magnesium
- Total phenols
- Flavanoids
- Nonflavanoid phenols
- Proanthocyanins
- Color intensity
- Hue
- OD280/OD315 of diluted wines
- Proline

Les données retravaillées à utiliser dans ce TD sont [[https://roland-donat.github.io/cours-class-non-sup/td/td1/wine.csv][disponibles à ici]].

* Modules =Python= utilisés dans ce TD

Dans ce TD, nous utiliserons les modules =Python= suivants :
- =pandas=, pour la manipulation des données ;
- =plotly=, pour les représentations graphiques ;
- =numpy=, pour utiliser des fonctions de calculs numériques "bas niveau", e.g. génération de
  nombres aléatoires ;
- =scipy=, pour utiliser d'autres fonctions de calculs numériques plus "haut niveau", e.g. calcul de
  distances.

Ces modules ne sont pas forcément installés dans votre environnement local ou en ligne. Vous pouvez
donc utiliser la commande =!pip install <nom_module>= pour les installer : 
#+attr_latex: :options bgcolor=almostwhite, frame=lines
#+BEGIN_SRC python :results silent :exports code
!pip install pandas=='1.2.5'
!pip install plotly=='5.6.0'
!pip install scipy=="1.7.3"
#+END_SRC
 

Rappel : code d'import des modules :
#+attr_latex: :options bgcolor=almostwhite, frame=lines
#+BEGIN_SRC python :results silent :exports code
import pandas as pd
import numpy as np
import plotly as pl
import plotly.express as px
import scipy as sc
import scipy.spatial.distance as scd
import sklearn as sk

# Vérification des versions des librairies utilisées
{"plotly": pl.__version__, 
 "pandas": pd.__version__, 
 "numpy": np.__version__, 
 "scipy": sc.__version__}
#+END_SRC


* Chargement des données et premières analyses

1. Chargez les données dans votre environnement à l'aide de la fonction =pd.read_csv=. 
   #+BEGIN_SRC python :results silent :exports code
data_path = "https://roland-donat.github.io/cours-class-non-sup/td/td1/wine.csv"
data_df = pd.read_csv(data_path, sep=",")
   #+END_SRC
2. Faites une rapide analyse exploratoire de vos données :
   - de manière macroscopique avec les méthodes =.head=, =.describe= et =.info=
   - de manière visuelle en représentant la distribution de chaque variable en utilisant la fonction
     =px.box=. 
     Que constatez vous ?
   #+BEGIN_SRC python :results silent :exports code
data_df.describe()
data_df.info()
px.box(data_df, title="Boxplot de chaque variable (donnée originale)")
   #+END_SRC
3. Centrez et réduisez les données. Aide : utilisez les méthodes =.mean= et =.std= des =DataFrame=.
   #+BEGIN_SRC python :results silent :exports code
data_scaled_df = <à compléter>
   #+END_SRC
4. Calculez la matrice des corrélations linéaires avec la méthode =.corr= des =DataFrame=. Quelles
   sont les caractéristiques remarquables de cette matrice ?
5. Affichez un diagramme en paire et une carte de chaleur des corrélations linéaires.
   #+BEGIN_SRC python :results silent :exports code
px.imshow(data_df.corr(), 
          color_continuous_midpoint=0, 
          title="Corrélations linéaires des données sous forme de carte de chaleur (heatmap)")
   #+END_SRC


* Distance euclidienne

*Dans la suite du TD, nous allons travailler avec les données centrées réduites calculées
précédemment dans le =DataFrame= =data_scaled_df=.* 

1. Calculez la distance euclidienne entre les deux premiers individus. Aide :
   utilisez la méthode =sum= des =DataFrame=.
2. Calculez la distance euclidienne entre le premier individu et le troisième, puis entre le
   deuxième et le troisième.
3. Calculez la matrice des distances euclidiennes. Aide : utilisez les fonctions =pdist= et
   =squareform= du package =scipy.spatial.distance=. Quelle sera la taille de cette matrice, quelles
   seront ses propriétés remarquables ?
   #+BEGIN_SRC python :results silent :exports code
scd.pdist(data_scaled_df, metric="euclidean")
scd.squareform(scd.pdist(data_scaled_df, metric="euclidean"))
   #+END_SRC
4. Transformez la matrice de distances précédente sous la forme d'un =DataFrame= pour en améliorer
   la lisibilité. Vérifiez que les distances calculées aux points 1 et 2 grâce à la matrice des distances calculée au
   point 3.

* Inertie totale

*Dans la suite du TD, les données seront considérées comme étant équipondérées avec un poids de 1
pour chaque observation. Par ailleurs, la distance utilisée sera la distance euclidienne.* 

*Nous travaillons toujours avec les données centrées réduites du =DataFrame= =data_scaled_df=.* 

1. Calculer le centre de gravité du nuage d'observations.
2. Calculer les distances au carré entre les observations et le centre de gravité du nuage. 
3. En déduire l'inertie totale des données.
4. Calculer la somme des variance empirique de chaque variable. Aide : utilisez la méthode =.var= des
   =DataFrame= ? Quels calculs fait exactement la méthode =.var= ? Aurait t-on pu prévoir le résultat
   dans ce cas ?
5. Comparez l'inertie totale avec la somme des variances des variables. 

* Première partition $C_{\text{A}}$

** Construction des classes

Nous allons nous donner une première partition $C_{\text{A}}$ totalement arbitraire consistant à affecter :
- la classe $c_{1}$ aux individus d'indices 0-49 ;
- la classe $c_{2}$ aux individus d'indices 50-99 ;
- la classe $c_{3}$ aux individus d'indices 100-177.

*Rappel :* N'oubliez pas que =Python= indexe les listes, vecteurs, tableaux en commençant à 0 !

1. Ajoutez une nouvelle variable =cls_A= contenant la classe de chaque individu suivant le schéma
   décrit précédemment.
   #+BEGIN_SRC python :results silent :exports code
data_scaled_df["cls_A"] = "c1"
data_scaled_df["cls_A"].loc[50:99] = "c2"
data_scaled_df["cls_A"].loc[100:] = "c3"
   #+END_SRC
2. Visualiser le nuage d'individus sur les variables =OD280= et =Alcohol= en faisant apparaître
   votre partition. Aide : utilisez la fonction =px.scatter= en utilisant l'option =color= pour
   colorer les individus en fonction de leur classe.


** Inertie intra-classe

1. Calculez le centre de gravité de chaque classe. Aide : utilisez la méthode =groupby= des
   =DataFrame= afin de regrouper les données sur la variable de classe et réaliser des traitements
   sur chaque groupe.
2. Calculez l'inertie interne de chaque classe.
3. En déduire l'inertie intra-classe de la partition.
4. En déduire l'inertie inter-classe de la partition.
5. Calculez le % d'inertie expliquée par la partition.
6. Calculez la somme des variances empiriques corrigées des variables au sein de chaque classe.
7. Comparez les inerties internes et le résultat de la question 6.
8. Comment calculer l'inertie intra-classe de la partition à partir de la question 6.


** Inertie inter-classe

1. Calculez le carré des distances entre le centre de gravité des classes et le centre de gravité
   des données.
2. En déduire l'inertie inter-classe de la partition.


* Seconde partition $C_{\text{B}}$

Reprendre les questions de la partie précédente en construisant une partition $C_{\text{B}}$ au
hasard. Pour ce faire, utilisez la fonction =np.ramdom.choice= pour affecter les classes aux
individus. N'hésitez pas à fixer la graine du générateur aléatoire avec la fonction =np.random.seed=
afin de reproduire le "même hasard" d'une exécution à l'autre de votre script. 

#+BEGIN_SRC python :results silent :exports code
# On fixe la graîne du générateur de nombre aléatoire pour 
# reproduire le même "hasard" d'une exécution à l'autre
np.random.seed(56)

# Initalisation au hasard de la partition
data_scaled_df["cls_B"] = np.random.choice(["c1", "c2", "c3"],
                                            len(data_scaled_df))

N_cls_B = data_scaled_df["cls_B"].value_counts()
N_cls_B
#+END_SRC
